--model-path meta-llama/Meta-Llama-3.1-8B-Instruct
--pipeline-parallel-size 2
--dtype bfloat16
--attention-backend triton
--mem-fraction-static 0.75
--disable-radix-cache
--served-model-name llama8b 